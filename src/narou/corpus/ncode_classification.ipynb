{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_feature_and_bin_classified_sentence_data import MultiFeatureAndBinClassifiedSentenceData\n",
    "from src.util import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_genre(ncode):\n",
    "    meta_file_path = corpus.create_meta_file_path(ncode)\n",
    "    with open(meta_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['biggenre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading embedding_model...\n"
     ]
    }
   ],
   "source": [
    "supplier = MultiFeatureAndBinClassifiedSentenceData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data dict...\n"
     ]
    }
   ],
   "source": [
    "raw_data_dict = supplier.multi_feature_and_bin_classified_sentence_data_dict(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_lower_limit = 0.35\n",
    "data_dict = raw_data_dict.copy()\n",
    "for ncode in raw_data_dict.keys():\n",
    "    if raw_data_dict[ncode]['rouge']['f'] < rouge_lower_limit:\n",
    "        del data_dict[ncode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = supplier.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncodes = list(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_story_ncodes = []\n",
    "fantasy_ncodes = []\n",
    "literature_ncodes = []\n",
    "sf_ncodes = []\n",
    "non_genre_ncodes = []\n",
    "other_ncodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ncode in ncodes:\n",
    "    bg = big_genre(ncode)\n",
    "    if bg == 1:\n",
    "        love_story_ncodes.append(ncode)\n",
    "    elif bg == 2:\n",
    "        fantasy_ncodes.append(ncode)\n",
    "    elif bg == 3:\n",
    "        literature_ncodes.append(ncode)\n",
    "    elif bg == 4:\n",
    "        sf_ncodes.append(ncode)\n",
    "    elif bg == 98:\n",
    "        non_genre_ncodes.append(ncode)\n",
    "    elif bg == 99:\n",
    "        other_ncodes.append(ncode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_story_train_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'love_story', 'train_data_ncodes.txt')\n",
    "love_story_test_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'love_story', 'test_data_ncodes.txt')\n",
    "fantasy_train_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'fantasy', 'train_data_ncodes.txt')\n",
    "fantasy_test_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'fantasy', 'test_data_ncodes.txt')\n",
    "literature_train_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'literature', 'train_data_ncodes.txt')\n",
    "literature_test_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'literature', 'test_data_ncodes.txt')\n",
    "sf_train_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'sf', 'train_data_ncodes.txt')\n",
    "sf_test_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'sf', 'test_data_ncodes.txt')\n",
    "non_genre_train_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'non_genre', 'train_data_ncodes.txt')\n",
    "non_genre_test_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'non_genre', 'test_data_ncodes.txt')\n",
    "other_train_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'other', 'train_data_ncodes.txt')\n",
    "other_test_path = os.path.join(settings.NAROU_MODEL_DIR_PATH, 'ncodes', 'other', 'test_data_ncodes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ncodes(train_ncodes_path, test_ncodes_path, ncodes, test_size=0.1):\n",
    "    train_ncodes = ncodes[:int(len(ncodes) * (1 - test_size))]\n",
    "    test_ncodes = ncodes[int(len(ncodes) * (1 - test_size)):]\n",
    "    print('saving splited data ncode...')\n",
    "    with open(train_ncodes_path, 'wb') as train_f:\n",
    "        joblib.dump(train_ncodes, train_f, compress=3)\n",
    "    with open(test_ncodes_path, 'wb') as test_f:\n",
    "        joblib.dump(test_ncodes, test_f, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving splited data ncode...\n",
      "saving splited data ncode...\n",
      "saving splited data ncode...\n",
      "saving splited data ncode...\n",
      "saving splited data ncode...\n",
      "saving splited data ncode...\n"
     ]
    }
   ],
   "source": [
    "save_ncodes(love_story_train_path, love_story_test_path, love_story_ncodes)\n",
    "save_ncodes(fantasy_train_path, fantasy_test_path, fantasy_ncodes)\n",
    "save_ncodes(literature_train_path, literature_test_path, literature_ncodes)\n",
    "save_ncodes(sf_train_path, sf_test_path, sf_ncodes)\n",
    "save_ncodes(non_genre_train_path, non_genre_test_path, non_genre_ncodes)\n",
    "save_ncodes(other_train_path, other_test_path, other_ncodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
